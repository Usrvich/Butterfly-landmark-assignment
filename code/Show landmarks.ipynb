{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7480fb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os    \n",
    "import random\n",
    "import shutil\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "import csv\n",
    "\n",
    "    \n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "\n",
    "# Flip image and landmark horizontally\n",
    "def symmetric_horizontal(image, landmarks):\n",
    "    image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    x_m = image.size[0] / 2\n",
    "    landmarks[:,0] = 2 * (x_m - landmarks[:,0]) + landmarks[:,0]    \n",
    "    return image, landmarks\n",
    "# Flip image and landmark vertically\n",
    "def symmetric_vertical(image, landmarks):\n",
    "    image = image.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "    y_m = image.size[1] / 2\n",
    "    landmarks[:,1] = 2 * (y_m - landmarks[:,1]) + landmarks[:,1]    \n",
    "    return image, landmarks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "168e1673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "def dev_train_val_test(train_p, val_p, test_p):\n",
    "    \"\"\"\n",
    "    This function is used to process the original dataset.\n",
    "    The argument train_p, val_p, test_p are the proportion of the training set, validation set and test set respectively.\n",
    "    In the original data set, some images do not have corresponding landmark labels, we need to clean up these images first.\n",
    "    Then, we need to divide the data set into training set, validation set and test set.\n",
    "    We check each image and its corresponding landmark labels, if the 10th landmark label is not in the upper left corner, corresponding symmertric transformation is performed.\n",
    "    Finally, we save the image path, image name and landmark labels in the csv file, and images are copied to the corresponding folder.\n",
    "\n",
    "    \"\"\"\n",
    "    image_path = \"C:\\\\Users\\\\14552\\\\Desktop\\\\project\\\\Heliconius_forewing_band-master\\\\images\"\n",
    "    landmark_path = \"C:\\\\Users\\\\14552\\\\Desktop\\\\project\\\\Heliconius_forewing_band-master\\\\landmarks\"\n",
    "    train_path = \"C:\\\\Users\\\\14552\\\\Desktop\\\\project\\\\Heliconius_forewing_band-master\\\\dataset_wash\\\\train\"\n",
    "    val_path = \"C:\\\\Users\\\\14552\\\\Desktop\\\\project\\\\Heliconius_forewing_band-master\\\\dataset_wash\\\\val\"\n",
    "    test_path = \"C:\\\\Users\\\\14552\\\\Desktop\\\\project\\\\Heliconius_forewing_band-master\\\\dataset_wash\\\\test\"\n",
    "    imagefolder_list = os.listdir(image_path)\n",
    "    landmarkfolder_list = os.listdir(landmark_path)\n",
    "    folder = set(imagefolder_list) & set(landmarkfolder_list)\n",
    "    images = []\n",
    "    landmarks = []\n",
    "    names = []\n",
    "    train_set = []\n",
    "    val_set = []\n",
    "    test_set = []\n",
    "    img_landmark_dict = {}\n",
    "    counter = 0\n",
    "    for i in folder:\n",
    "        i_path = os.path.join(image_path, i)\n",
    "        l_path = os.path.join(landmark_path, i)\n",
    "        i_list = os.listdir(i_path)\n",
    "        l_list = os.listdir(l_path)\n",
    "        for image in i_list:\n",
    "            for landmark in l_list:\n",
    "                image_copy = image\n",
    "                img_name = image_copy.split('.')[0]\n",
    "                if img_name in landmark and image[-4:] != \".ini\" and image[-4:] != \".txt\":\n",
    "                    counter += 1\n",
    "                    images.append(os.path.join(i_path, image))\n",
    "                    landmarks.append(os.path.join(l_path, landmark))\n",
    "                    names.append(img_name)\n",
    "                    img_landmark = np.loadtxt(os.path.join(l_path, landmark), delimiter=\"\\t\", usecols=(0,1), skiprows=0)\n",
    "                    img_landmark_dict[os.path.join(i_path, image)] = img_landmark.tolist()\n",
    "    # with open(\"test.csv\", \"w\", newline='') as f:\n",
    "    #     writer = csv.writer(f)\n",
    "    #     writer.writerow([\"image_name\", \"landmarks\"])\n",
    "    #     for key, value in img_landmark_dict.items():\n",
    "    #         writer.writerow([key, value])\n",
    "    data_nums = len(img_landmark_dict)\n",
    "    valid_imgs = list(img_landmark_dict.keys())\n",
    "    offset_0 = int(data_nums * train_p)\n",
    "    offset_1 = int(data_nums * (train_p + val_p))\n",
    "    offset_2 = int(data_nums * (train_p + val_p + test_p))\n",
    "    random.seed(2023)\n",
    "    random.shuffle(valid_imgs)\n",
    "    print(len(valid_imgs))\n",
    "    \n",
    "    train_set = valid_imgs[:offset_0]\n",
    "    val_set = valid_imgs[offset_0:offset_1]\n",
    "    test_set = valid_imgs[offset_1:offset_2]\n",
    "\n",
    "    with open(os.path.join(train_path, \"train.csv\"), \"w\", newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"image_path\", \"image_name\", \"landmarks\"])\n",
    "        for i in range(len(train_set)):\n",
    "            image = Image.open(train_set[i])\n",
    "            width, height = image.size\n",
    "            landmark = np.array(img_landmark_dict[train_set[i]])\n",
    "            if landmark[10][0] > width / 2:\n",
    "                if landmark[10][1] > height / 2:\n",
    "                    image, landmark = symmetric_horizontal(image, landmark)\n",
    "                    image, landmark = symmetric_vertical(image, landmark)\n",
    "                else:\n",
    "                    image, landmark = symmetric_horizontal(image, landmark)\n",
    "            elif landmark[10][1] > height / 2:\n",
    "                image, landmark = symmetric_vertical(image, landmark)\n",
    "\n",
    "            image.save(os.path.join(train_path, train_set[i].split(\"\\\\\")[-1]))\n",
    "            writer.writerow([train_set[i], train_set[i].split(\"\\\\\")[-1], landmark.tolist()])\n",
    "    f.close()\n",
    "\n",
    "    with open(os.path.join(val_path, \"val.csv\"), \"w\", newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"image_path\", \"image_name\", \"landmarks\"])\n",
    "        for i in range(len(val_set)):\n",
    "            image = Image.open(val_set[i])\n",
    "            width, height = image.size\n",
    "            landmark = np.array(img_landmark_dict[val_set[i]])\n",
    "            if landmark[10][0] > width / 2:\n",
    "                if landmark[10][1] > height / 2:\n",
    "                    image, landmark = symmetric_horizontal(image, landmark)\n",
    "                    image, landmark = symmetric_vertical(image, landmark)\n",
    "                else:\n",
    "                    image, landmark = symmetric_horizontal(image, landmark)\n",
    "            elif landmark[10][1] > height / 2:\n",
    "                image, landmark = symmetric_vertical(image, landmark)\n",
    "\n",
    "            image.save(os.path.join(val_path, val_set[i].split(\"\\\\\")[-1]))\n",
    "            writer.writerow([val_set[i], val_set[i].split(\"\\\\\")[-1], landmark.tolist()])\n",
    "    f.close()\n",
    "    \n",
    "    with open(os.path.join(test_path, \"test.csv\"), \"w\", newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"image_path\", \"image_name\", \"landmarks\"])\n",
    "        for i in range(len(test_set)):\n",
    "            image = Image.open(test_set[i])\n",
    "            width, height = image.size\n",
    "            landmark = np.array(img_landmark_dict[test_set[i]])\n",
    "            if landmark[10][0] > width / 2:\n",
    "                if landmark[10][1] > height / 2:\n",
    "                    image, landmark = symmetric_horizontal(image, landmark)\n",
    "                    image, landmark = symmetric_vertical(image, landmark)\n",
    "                else:\n",
    "                    image, landmark = symmetric_horizontal(image, landmark)\n",
    "            elif landmark[10][1] > height / 2:\n",
    "                image, landmark = symmetric_vertical(image, landmark)\n",
    "\n",
    "            image.save(os.path.join(test_path, test_set[i].split(\"\\\\\")[-1]))\n",
    "            writer.writerow([test_set[i], test_set[i].split(\"\\\\\")[-1], landmark.tolist()])\n",
    "    f.close()\n",
    "\n",
    "\n",
    "dev_train_val_test(0.7, 0.1, 0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
